---
module-name: my-llm-app
version: 0.1.0
description: A Next.js-based application that provides LLM-powered features including chat interface, audio transcription, and resume analysis capabilities.
related-modules:
  - name: electron-wrapper
    path: ./electron
technologies:
  - Next.js 15.0.3
  - React (latest)
  - TypeScript
  - Tailwind CSS
  - Prisma
  - NextAuth.js
  - Radix UI Components
  - Electron
  - OpenAI SDK
  - Anthropic SDK
conventions:
  - Use TypeScript for all new code
  - Follow React hooks pattern for state management
  - Implement responsive design using Tailwind CSS
  - Use Radix UI for accessible component primitives
  - Follow Next.js App Router conventions
  - Implement proper error boundaries
directives:
  - All API routes must implement proper error handling
  - Authentication required for all protected routes
  - Use environment variables for sensitive configuration
  - Maintain TypeScript strict mode compliance
diagrams:
  - name: Application Architecture
    path: ./docs/diagrams/architecture.mermaid
  - name: Authentication Flow
    path: ./docs/diagrams/auth-flow.mermaid
architecture:
  style: Monolithic Next.js Application with Electron wrapper
  components:
    - Next.js Frontend (React + TypeScript)
    - Next.js API Routes (Backend)
    - Prisma Database Layer
    - Authentication System (NextAuth.js)
    - LLM Integration Services
    - Audio Processing System
    - Electron Desktop Wrapper
  data-flow:
    - Client requests flow through Next.js App Router
    - API routes handle backend operations
    - Authentication via NextAuth.js middleware
    - Database operations through Prisma client
    - LLM requests proxied through backend services
development:
  setup-steps:
    - Clone repository
    - Install Node.js 18+ and npm
    - Run npm install for dependencies
    - Configure environment variables
    - Initialize Prisma database
    - Start development server
  build-command: npm run build
  test-command: npm run test
business-requirements:
  key-features:
    - LLM-powered chat interface
    - Real-time audio transcription
    - Resume analysis and optimization
    - Document management system
    - Authentication and user management
  target-audience: Professionals and developers seeking AI-powered tools
  success-metrics:
    - User engagement metrics
    - Transcription accuracy rate
    - Resume optimization effectiveness
    - System response time
    - User retention rate
quality-assurance:
  testing-frameworks:
    - Jest
    - React Testing Library
    - Prisma integration tests
  coverage-threshold: 80%
  performance-benchmarks:
    - API response time under 500ms
    - Chat completion under 2 seconds
    - Audio transcription real-time performance
deployment:
  platform: Vercel
  cicd-pipeline: GitHub Actions
  staging-environment: https://staging.my-llm-app.vercel.app
  production-environment: https://my-llm-app.vercel.app
---

# My LLM App

A comprehensive Next.js application that leverages Large Language Models (LLMs) to provide intelligent features including chat interfaces, audio transcription, and resume analysis capabilities. The application is designed to be deployed as both a web service and a desktop application through Electron.

## Architecture Overview

The application follows a monolithic architecture built on Next.js, combining frontend and backend capabilities in a single codebase. The architecture is organized into several key components:

- Frontend Layer: Built with React and TypeScript, utilizing Radix UI components and Tailwind CSS for styling
- API Layer: Next.js API routes handling backend operations
- Database Layer: Prisma ORM managing data persistence
- Authentication: NextAuth.js providing secure user authentication
- LLM Integration: Services for OpenAI and Anthropic API interactions
- Audio Processing: Real-time audio transcription system
- Desktop Integration: Electron wrapper for desktop deployment

## Development Guidelines

1. Code Organization:
   - Follow Next.js 13+ App Router structure
   - Maintain clear separation of concerns
   - Use TypeScript for type safety
   - Implement proper error handling

2. State Management:
   - Use React hooks for local state
   - Implement context where needed
   - Follow immutability patterns

3. Styling:
   - Use Tailwind CSS for styling
   - Maintain responsive design
   - Follow accessibility guidelines

4. Testing:
   - Write unit tests for components
   - Implement integration tests
   - Maintain code coverage standards

## Business Context

The application serves professionals and developers seeking AI-powered tools for various tasks. Key objectives include:

1. Providing intuitive access to LLM capabilities
2. Enabling efficient audio transcription
3. Offering intelligent resume analysis
4. Maintaining high performance and reliability

Success is measured through user engagement, feature accuracy, and system performance metrics.

## Quality Assurance

Quality is maintained through:

1. Comprehensive testing strategy:
   - Unit tests for components and utilities
   - Integration tests for API routes
   - End-to-end tests for critical flows

2. Performance monitoring:
   - Regular performance audits
   - Response time tracking
   - Error rate monitoring

3. Code review process:
   - Peer reviews required
   - Automated linting and type checking
   - Coverage requirements

## Deployment and Operations

The application follows a robust deployment process:

1. Continuous Integration:
   - Automated testing on pull requests
   - Build verification
   - Type checking and linting

2. Deployment Stages:
   - Development environment for active development
   - Staging for pre-release testing
   - Production for end-user access

3. Monitoring:
   - Performance metrics tracking
   - Error logging and alerting
   - Usage analytics
